---
title: "Untitled"
output: pdf_document
latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
message = FALSE
```

## President Sentiment Analysis 
Lydon B Johnson gave his state of the union address in 1964 and Ford in 1975. According to the data, LBJ had a 59% positivty rate (139/233 tokenized words) with his most frequent words used being 'faith' (8 times), 'good' (6 times) and 'create' (4 times). Likewise, Ford had a 61% positivity rate (230/378 tokenized words) with his most used words being 'public' (11), 'faith' (8) and 'time' (7). The analysis for both presidents had a fairly positive sentiment rate (Even though they both were not elected!). 

```{r}
library(tidytext)
library(tidyverse)
library(ggplot2)

#get txt file
LBJ <- data_frame(name="LBJ", text = read_lines("LBJ.txt"))
Ford <- data_frame(name="Ford", text = read_lines("Ford.txt"))

#tokenize data
tokenized1 <- LBJ %>% unnest_tokens(word, text)
tokenized2 <- Ford %>% unnest_tokens(word, text)
  
nrc_anticipation <- get_sentiments("nrc") %>% 
  filter(sentiment == "anticipation")

nrc_anger <- get_sentiments("nrc") %>% 
  filter(sentiment == "anger")

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")
```
##  LBJ Word Counts 
```{r}
joy <- tokenized1 %>%
  filter(name == "LBJ") %>% inner_join(nrc_joy) %>% count(word, sort = TRUE)
joy

anticipation <- tokenized1 %>%
  filter(name == "LBJ") %>% inner_join(nrc_anticipation) %>% count(word, sort = TRUE)
anticipation
  
anger <- tokenized1 %>%
  filter(name == "LBJ") %>% inner_join(nrc_anger) %>% count(word, sort = TRUE)
anger

# get the sentiment from the LBJ: 
sentiment <- tokenized1 %>%
  inner_join(get_sentiments("bing")) %>% 
  count(sentiment) %>% 
  spread(sentiment, n, fill = 0) %>% 
  mutate(sentiment = positive - negative) 
sentiment
```
## Ford Word Counts 
```{r}
# get the sentiment from the Ford: 
sentiment2 <- tokenized2 %>%
  inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
  count(sentiment) %>% # count the # of positive & negative words
  spread(sentiment, n, fill = 0) %>% 
  mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
sentiment2
```
```{r}
# sentiments for every word in file
tidy_pres <- tokenized1 %>%
  inner_join(get_sentiments("nrc"))
#tidy_pres

tidy_pres2 <- tokenized2 %>%
  inner_join(get_sentiments("nrc"))
#tidy_pres2
```


## LBJ Sentiment 

```{r}
nrc_plot <- tidy_pres %>%
  group_by(sentiment) %>%
  summarise(word_count = n()) %>%
  ungroup() %>%
  mutate(sentiment = reorder(sentiment, word_count)) %>%

  ggplot(aes(sentiment, word_count, fill = -word_count)) +
  geom_col() +
  guides(fill = FALSE) + 
  labs(x = NULL, y = "Word Count") +
  scale_y_continuous(limits = c(0, 300)) + 
  ggtitle("LBJ Sentiment") +
  coord_flip()
nrc_plot
```

## Ford Sentiment 
```{r}

#barplot for Ford
nrc_plot2 <- tidy_pres2 %>%
  group_by(sentiment) %>%
  summarise(word_count = n()) %>%
  ungroup() %>%
  mutate(sentiment2 = reorder(sentiment, word_count)) %>%
  
  ggplot(aes(sentiment2, word_count, fill = -word_count)) +
  geom_col() +
  guides(fill = FALSE) + 
  labs(x = NULL, y = "Word Count") +
  scale_y_continuous(limits = c(0, 300)) + 
  ggtitle("Ford Sentiment") +
  coord_flip()
nrc_plot2
```